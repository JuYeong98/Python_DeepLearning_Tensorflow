{"metadata":{"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Keras fashion mnist dataset을 다운로드\n* 5만개의 학습용, 1만개의 테스트용 grayscale image array를 다운로드","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.datasets import fashion_mnist\n\n# 전체 6만개 데이터 중, 5만개는 학습 데이터용, 1만개는 테스트 데이터용으로 분리\n(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n# image size는 28x28의 grayscale 2차원 데이터\nprint(\"train dataset shape:\", train_images.shape, train_labels.shape)\nprint(\"test dataset shape:\", test_images.shape, test_labels.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### MNIST image array 시각화","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\n\nplt.imshow(train_images[0], cmap='gray')\nplt.title(train_labels[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_images[0, :, :], train_labels[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline \n\nclass_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat','Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n\ndef show_images(images, labels, ncols=8):\n    figure, axs = plt.subplots(figsize=(22, 6), nrows=1, ncols=ncols)\n    for i in range(ncols):\n        axs[i].imshow(images[i], cmap='gray')\n        axs[i].set_title(class_names[labels[i]])\n        \nshow_images(train_images[:8], train_labels[:8], ncols=8)\nshow_images(train_images[8:16], train_labels[8:16], ncols=8)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 데이터 전처리 수행. \n* 0 ~ 255 사이의 픽셀값을 0 ~ 1 사이 값으로 변환. \n* array type은 float 32","metadata":{}},{"cell_type":"code","source":"(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n\ndef get_preprocessed_data(images, labels):\n    \n    # 학습과 테스트 이미지 array를 0~1 사이값으로 scale 및 float32 형 변형. \n    images = np.array(images/255.0, dtype=np.float32)\n    labels = np.array(labels, dtype=np.float32)\n    \n    return images, labels\n\ntrain_images, train_labels = get_preprocessed_data(train_images, train_labels)\ntest_images, test_labels = get_preprocessed_data(test_images, test_labels)\n\nprint(\"train dataset shape:\", train_images.shape, train_labels.shape)\nprint(\"test dataset shape:\", test_images.shape, test_labels.shape)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_images[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dense Layer를 기반으로 모델을 생성","metadata":{}},{"cell_type":"code","source":"INPUT_SIZE = 28","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Dense, Flatten\nfrom tensorflow.keras.models import Sequential\n\nmodel = Sequential([\n    Flatten(input_shape=(INPUT_SIZE, INPUT_SIZE)),\n    Dense(100, activation='relu'),\n    Dense(30, activation='relu'),\n    Dense(10, activation='softmax')\n])\n\nmodel.summary()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 모델의 Loss와 Optimizer 설정하고 학습 수행\n* loss는 categorical_crossentropy로, optimizer는 Adam으로 설정\n* categorical crossentropy를 위해서 Lable을 OHE 로 변경","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import CategoricalCrossentropy\nfrom tensorflow.keras.metrics import Accuracy\n\nmodel.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import to_categorical\n\ntrain_oh_labels = to_categorical(train_labels)\ntest_oh_labels = to_categorical(test_labels)\n\nprint(train_oh_labels.shape, test_oh_labels.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_images.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(x=train_images, y=train_oh_labels, batch_size=32, epochs=20, verbose=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(history.history['loss'])\nprint(history.history['accuracy'])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 테스트 데이터를 기반으로 Label 값 예측\n* model.predict()를 이용하여 label값 예측\n* predict()의 인자로 입력되는 feature array는 학습의 feature array와 shape가 동일해야함. \n* fit() 시 3차원(28x28 2차원 array가 여러개 존재) array 입력 했으므로 predict()도 동일한 3차원 데이터 입력\n* 특히 한건만 predict() 할때도 3차원 데이터여야 함. 이를 위해 expand_dims()로 2차원 image 배열을 3차원으로 변경","metadata":{}},{"cell_type":"code","source":"test_images.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_proba = model.predict(test_images)\nprint(pred_proba.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.expand_dims(test_images[0], axis=0).shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_proba = model.predict(np.expand_dims(test_images[0], axis=0))\nprint('softmax output:', pred_proba)\npred = np.argmax(np.squeeze(pred_proba))\nprint('predicted class value:', pred)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat','Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\nprint('target class value:', test_labels[0], 'predicted class value:', pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 테스트 데이터 세트로 모델 성능 검증","metadata":{}},{"cell_type":"code","source":"model.evaluate(test_images, test_oh_labels, batch_size=64)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 검증 데이터 세트를 이용하여 학습 수행. \n* 일반적으로 fit() 수행시 별도의 검증 데이터 세트를 이용하여 학습 시 과적합(Overfitting)이 발생하는지 모니터링\n* fit()을 수행하면 iteration을 반복하기 때문에 중간에 하이퍼파라미터 변경(예: Learning Rate)등의 작업이 어려움. \n* fit() iteration시 여러 작업을 하기 위해 Callback 객체를 가짐. \n* 검증 데이터 세트를 fit() 시 적용하여 과적합이나 더이상 검증 데이터 성능이 좋아 지지 않을 때 Callback을 사용하여 Learning Rate 보정 작업등을 수행 가능","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nfrom tensorflow.keras.datasets import fashion_mnist\n\n(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n\ndef get_preprocessed_data(images, labels):\n    \n    # 학습과 테스트 이미지 array를 0~1 사이값으로 scale 및 float32 형 변형. \n    images = np.array(images/255.0, dtype=np.float32)\n    labels = np.array(labels, dtype=np.float32)\n    \n    return images, labels\n\ntrain_images, train_labels = get_preprocessed_data(train_images, train_labels)\ntest_images, test_labels = get_preprocessed_data(test_images, test_labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import to_categorical\n\n# 기존 학습 데이터를 다시 학습과 검증 데이터 세트로 분리\ntr_images, val_images, tr_labels, val_labels = train_test_split(train_images, train_labels, test_size=0.15, random_state=2021)\nprint('train과 validation shape:', tr_images.shape, tr_labels.shape, val_images.shape, val_labels.shape)\n\n# OHE 적용\ntr_oh_labels = to_categorical(tr_labels)\nval_oh_labels = to_categorical(val_labels)\n\nprint('after OHE:', tr_oh_labels.shape, val_oh_labels.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 검증 데이터 세트를 적용하여 학습 수행. ","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Dense, Flatten\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam\n\nINPUT_SIZE = 28\nmodel = Sequential([\n    Flatten(input_shape=(INPUT_SIZE, INPUT_SIZE)),\n    Dense(100, activation='relu'),\n    Dense(30, activation='relu'),\n    Dense(10, activation='softmax')\n])\n\nmodel.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(x=tr_images, y=tr_oh_labels, batch_size=128, validation_data=(val_images, val_oh_labels), \n                    epochs=20, verbose=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(history.history['loss'])\nprint(history.history['accuracy'])\nprint(history.history['val_loss'])\nprint(history.history['val_accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\n\nplt.plot(history.history['accuracy'], label='train')\nplt.plot(history.history['val_accuracy'], label='valid')\nplt.legend()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Functional API","metadata":{}},{"cell_type":"code","source":"# Sequential Model을 이용하여 Keras 모델 생성 \nfrom tensorflow.keras.layers import Dense, Flatten\nfrom tensorflow.keras.models import Sequential\n\nINPUT_SIZE = 28\n\nmodel = Sequential([\n    Flatten(input_shape=(INPUT_SIZE, INPUT_SIZE)),\n    Dense(100, activation='relu'),\n    Dense(30, activation='relu'),\n    Dense(10, activation='softmax')\n])\n\nmodel.summary()\n\nmodel1 = Sequential()\nmodel1.add(Flatten(input_shape=(INPUT_SIZE, INPUT_SIZE)))\nmodel1.add(Dense(100, activation='relu'))\nmodel1.add(Dense(30, activation='relu'))\nmodel1.add(Dense(10, activation='softmax'))\n\nmodel1.summary()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Input, Flatten, Dense\nfrom tensorflow.keras.models import Model\n\ninput_tensor = Input(shape=(INPUT_SIZE, INPUT_SIZE))\nx = Flatten()(input_tensor)\nx = Dense(100, activation='relu')(x)\nx = Dense(30, activation='relu')(x)\noutput = Dense(10, activation='softmax')(x)\n\nmodel = Model(inputs=input_tensor, outputs=output)\n\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Custom한 Dense Layer 생성하기","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.layers import Layer, Input\nfrom tensorflow.keras.models import Model\nimport tensorflow as tf\n\nclass CustomDense(tf.keras.layers.Layer):\n    # CustomDense 객체 생성시 입력되는 초기화 parameter 처리\n    def __init__(self, units=32):\n        super(CustomDense, self).__init__()\n        self.units = units\n\n    def build(self, input_shape):\n        self.w = self.add_weight(\n            shape=(input_shape[-1], self.units),\n            initializer=\"random_normal\",\n            trainable=True,\n        )\n        self.b = self.add_weight(\n            shape=(self.units,), initializer=\"random_normal\", trainable=True\n        )\n        \n    # CustomDense 객체에 callable로 입력된 입력 데이터 처리. \n    def call(self, inputs):\n        return tf.matmul(inputs, self.w) + self.b\n\n# input 값을 4개의 원소를 가지는 1차원으로 생성. \ninputs = Input((4,))\n# 10개의 unit을 가지는 CustomDense 객체를 생성 후 callable로 inputs값 입력 \noutputs = CustomDense(10)(inputs)\n\n# inputs와 outputs로 model 생성. \nmodel = Model(inputs, outputs)\nmodel.summary()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Functional API는 객체 생성 부분과 Callable 인자 입력 부분을 별도로 수행해도 무방. ","metadata":{}},{"cell_type":"code","source":"inputs = Input((4,))\n# 10개의 unit을 가지는 CustomDense 객체를 생성 후 callable로 inputs값 입력 \nmy_layer = CustomDense(10)\noutputs = my_layer(inputs)\n\n# inputs와 outputs로 model 생성. \nmodel = Model(inputs, outputs)\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Sequential Model 생성은 단지 Functional API Layer들을 iteration 하면서 연결한 것을 model로 만든 것임","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\n\nmodel = Sequential([Input((4,)),\n                   CustomDense(10),\n                   CustomDense(8), \n                   tf.keras.layers.ReLU()])\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Sequential Model을 Functional 객체를 For loop 반복 호출하여 작성.","metadata":{}},{"cell_type":"code","source":"layers_list = [Input((4,)), CustomDense(10), CustomDense(8), tf.keras.layers.ReLU()]\n\nfor index, layer in enumerate(layers_list):\n        print(index, layer)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"layers_list = [Input((4,)), CustomDense(10), CustomDense(8), tf.keras.layers.ReLU()]\n\ninputs = None\ncallable_inputs = None\noutputs = None\n# layers_list에 있는 Functional 객체를 iteration 수행하면서 적용. \nfor index, layer in enumerate(layers_list):\n    # layers_list의 첫번째 인자는 Input 간주. \n    if index == 0:\n        inputs = layer\n        callable_inputs = layer\n    # Functional 객체에 callable 인자로 callable_inputs를 입력하고 반환 결과 값을 다시 callable_inputs로 할당.     \n    else: \n        callable_inputs = layer(callable_inputs)\n    \noutputs = callable_inputs\nmodel = Model(inputs, outputs)\nmodel.summary()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 앞에서 생성한 로직들을 함수화 \n* Functional API로 모델 만들기\n* pixel값 1 ~ 255를 0 ~ 1사이값 Float 32로 만들기\n* One Hot Encoding Label에 적용하기\n* 학습과 검증 데이터로 나누기.\n* compile, 학습/예측/평가","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.layers import Layer, Input, Dense, Flatten\nfrom tensorflow.keras.models import Model\nimport tensorflow as tf\n\nINPUT_SIZE = 28\n\ndef create_model():\n    input_tensor = Input(shape=(INPUT_SIZE, INPUT_SIZE))\n    x = Flatten()(input_tensor)\n    x = Dense(100, activation='relu')(x)\n    x = Dense(30, activation='relu')(x)\n    output = Dense(10, activation='softmax')(x)\n    \n    model = Model(inputs=input_tensor, outputs=output)\n    return model\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\n\n# 0 ~ 1사이값의 float32로 변경하는 함수\ndef get_preprocessed_data(images, labels):\n    \n    # 학습과 테스트 이미지 array를 0~1 사이값으로 scale 및 float32 형 변형. \n    images = np.array(images/255.0, dtype=np.float32)\n    labels = np.array(labels, dtype=np.float32)\n    \n    return images, labels\n\n# 0 ~ 1사이값 float32로 변경하는 함수 호출 한 뒤 OHE 적용 \ndef get_preprocessed_ohe(images, labels):\n    images, labels = get_preprocessed_data(images, labels)\n    # OHE 적용 \n    oh_labels = to_categorical(labels)\n    return images, oh_labels\n\n# 학습/검증/테스트 데이터 세트에 전처리 및 OHE 적용한 뒤 반환 \ndef get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021):\n    # 학습 및 테스트 데이터 세트를  0 ~ 1사이값 float32로 변경 및 OHE 적용. \n    train_images, train_oh_labels = get_preprocessed_ohe(train_images, train_labels)\n    test_images, test_oh_labels = get_preprocessed_ohe(test_images, test_labels)\n    \n    # 학습 데이터를 검증 데이터 세트로 다시 분리\n    tr_images, val_images, tr_oh_labels, val_oh_labels = train_test_split(train_images, train_oh_labels, test_size=valid_size, random_state=random_state)\n    \n    return (tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels ) \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.datasets import fashion_mnist\n# Fashion MNIST 데이터 재 로딩 및 전처리 적용하여 학습/검증/데이터 세트 생성. \n\n(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\nprint(train_images.shape, train_labels.shape, test_images.shape, test_labels.shape)\n(tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels) = \\\n    get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021)\nprint(tr_images.shape, tr_oh_labels.shape, val_images.shape, val_oh_labels.shape, test_images.shape, test_labels.shape)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\n\n# Model 생성 및 optimizer, loss, metric 적용\nmodel = create_model()\nmodel.summary()\n\nmodel.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 학습 수행. \nhistory = model.fit(x=tr_images, y=tr_oh_labels, batch_size=128, epochs=20, validation_data=(val_images, val_oh_labels))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\n\ndef show_history(history):\n    plt.plot(history.history['accuracy'], label='train')\n    plt.plot(history.history['val_accuracy'], label='valid')\n    plt.legend()\n    \nshow_history(history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 테스트 데이터 세트로 모델 성능 검증\nmodel.evaluate(test_images, test_oh_labels, batch_size=256, verbose=1)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Callback ","metadata":{}},{"cell_type":"markdown","source":"#### ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n* 특정 조건에 맞춰서 모델을 파일로 저장\n* filepath: filepath는 (on_epoch_end에서 전달되는) epoch의 값과 logs의 키로 채워진 이름 형식 옵션을 가질 수 있음.\n예를 들어 filepath가 weights.{epoch:02d}-{val_loss:.2f}.hdf5라면, 파일 이름에 세대 번호와 검증 손실을 넣어 모델의 체크포인트가 저장 \n* monitor: 모니터할 지표(loss 또는 평가 지표) \n* save_best_only: 가장 좋은 성능을 나타내는 모델만 저장할 여부\n* save_weights_only: Weights만 저장할 지 여부 \n* mode: {auto, min, max} 중 하나. monitor 지표가 감소해야 좋을 경우 min, 증가해야 좋을 경우 max, auto는 monitor 이름에서 자동으로 유추. ","metadata":{}},{"cell_type":"code","source":"!pwd","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint\n\nmodel = create_model()\nmodel.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n\nmcp_cb = ModelCheckpoint(filepath='/kaggle/working/weights.{epoch:02d}-{val_loss:.2f}.hdf5', monitor='val_loss', \n                         save_best_only=True, save_weights_only=True, mode='min', period=3, verbose=1)\nhistory = model.fit(x=tr_images, y=tr_oh_labels, batch_size=128, epochs=10, validation_data=(val_images, val_oh_labels),\n                   callbacks=[mcp_cb])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls -lia\n#!rm -rf weight*\n#!ls -lia\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=0, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\n* 특정 epochs 횟수동안 성능이 개선 되지 않을 시 Learning rate를 동적으로 감소 시킴 \n* monitor: 모니터할 지표(loss 또는 평가 지표) \n* factor: 학습 속도를 줄일 인수. new_lr = lr * factor \n* patience: Learing Rate를 줄이기 전에 monitor할 epochs 횟수. \n* mode: {auto, min, max} 중 하나. monitor 지표가 감소해야 좋을 경우 min, 증가해야 좋을 경우 max, auto는 monitor 이름에서 유추. ","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ReduceLROnPlateau\n\nmodel = create_model()\nmodel.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n\nrlr_cb = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=3, mode='min', verbose=1)\nhistory = model.fit(x=tr_images, y=tr_oh_labels, batch_size=128, epochs=30, validation_data=(val_images, val_oh_labels),\n                   callbacks=[rlr_cb])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto', baseline=None, restore_best_weights=False)\n* 특정 epochs 동안 성능이 개선되지 않을 시 학습을 조기에 중단\n* monitor: 모니터할 지표(loss 또는 평가 지표) \n* patience: Early Stopping 적용 전에 monitor할 epochs 횟수. \n* mode: {auto, min, max} 중 하나. monitor 지표가 감소해야 좋을 경우 min, 증가해야 좋을 경우 max, auto는 monitor 이름에서 유추. ","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping\n\nmodel = create_model()\nmodel.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n\nely_cb = EarlyStopping(monitor='val_loss', patience=3, mode='min', verbose=1)\nhistory = model.fit(x=tr_images, y=tr_oh_labels, batch_size=128, epochs=30, validation_data=(val_images, val_oh_labels),\n                   callbacks=[ely_cb])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm weigh*","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n\nmodel = create_model()\nmodel.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n\nmcp_cb = ModelCheckpoint(filepath='/kaggle/working/weights.{epoch:02d}-{val_loss:.2f}.hdf5', monitor='val_loss', \n                         save_best_only=True, save_weights_only=True, mode='min', period=1, verbose=0)\nrlr_cb = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=5, mode='min', verbose=1)\nely_cb = EarlyStopping(monitor='val_loss', patience=7, mode='min', verbose=1)\n\nhistory = model.fit(x=tr_images, y=tr_oh_labels, batch_size=128, epochs=40, validation_data=(val_images, val_oh_labels),\n                   callbacks=[mcp_cb, rlr_cb, ely_cb])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls -lia","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}