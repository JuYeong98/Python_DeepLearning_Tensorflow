{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### identity block을 생성하는 함수인 identity_block() 생성. \n* input_tensor는 입력 tensor\n* kernel_size는 kernel 크기. identity block내에 있는 두개의 conv layer중 1x1 kernel이 아니고, 3x3 kernel임. 3x3 커널이 아니라 5x5 kernel도 지정할 수 있게 구성. \n* filters: 3개 conv layer들의 filter개수를 list 형태로 입력 받음. 첫번째 원소는 첫번째 1x1 filter 개수, 두번째는 3x3 filter 개수, 세번째는 마지막 1x1 filter 개수. 첫번재 1x1은 입력 tensor의 channel 차원을 1/4로 축소. 마지막 1x1 conv에서 다시 입력 tensor의 차원 복구\n* stage: identity block들이 여러개가 결합되므로 이를 구분하기 위해서 설정. 동일한 filter수를 가지는 identity block들을  동일한 stage로 설정.  \n* block: 동일 stage내에서 identity block을 구별하기 위한 구분자\n![](https://raw.githubusercontent.com/chulminkw/CNN_PG/main/utils/images/residual_block_small.png)\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.layers import Conv2D, Dense, BatchNormalization, Activation\nfrom tensorflow.keras.layers import add, Add\n\n# identity block은 shortcut 단에 conv layer가 없는 block 영역\ndef identity_block(input_tensor, middle_kernel_size, filters, stage, block):\n    '''\n    함수 입력 인자 설명\n    input_tensor는 입력 tensor\n    middle_kernel_size 중간에 위치하는 kernel 크기. identity block내에 있는 두개의 conv layer중 1x1 kernel이 아니고, 3x3 kernel임. \n    3x3 커널이 이외에도 5x5 kernel도 지정할 수 있게 구성. \n    filters: 3개 conv layer들의 filter개수를 list 형태로 입력 받음. 첫번째 원소는 첫번째 1x1 filter 개수, 두번째는 3x3 filter 개수, 세번째는 마지막 1x1 filter 개수\n    stage: identity block들이 여러개가 결합되므로 이를 구분하기 위해서 설정. 동일한 filter수를 가지는 identity block들을  동일한 stage로 설정.  \n    block: 동일 stage내에서 identity block을 구별하기 위한 구분자\n    ''' \n    \n    # filters로 list 형태로 입력된 filter 개수를 각각 filter1, filter2, filter3로 할당. \n    # filter은 첫번째 1x1 filter 개수, filter2는 3x3 filter개수, filter3는 마지막 1x1 filter개수\n    filter1, filter2, filter3 = filters\n    # conv layer와 Batch normalization layer각각에 고유한 이름을 부여하기 위해 설정. 입력받은 stage와 block에 기반하여 이름 부여\n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n    \n    # 이전 layer에 입력 받은 input_tensor(함수인자로 입력받음)를 기반으로 첫번째 1x1 Conv->Batch Norm->Relu 수행. \n    # 첫번째 1x1 Conv에서 Channel Dimension Reduction 수행. filter1은 입력 input_tensor(입력 Feature Map) Channel 차원 개수의 1/4임. \n    x = Conv2D(filters=filter1, kernel_size=(1, 1), kernel_initializer='he_normal', name=conv_name_base+'2a')(input_tensor)\n    # Batch Norm적용. 입력 데이터는 batch 사이즈까지 포함하여 4차원임(batch_size, height, width, channel depth)임\n    # Batch Norm의 axis는 channel depth에 해당하는 axis index인 3을 입력.(무조건 channel이 마지막 차원의 값으로 입력된다고 가정. )\n    x = BatchNormalization(axis=3, name=bn_name_base+'2a')(x)\n    # ReLU Activation 적용. \n    x = Activation('relu')(x)\n    \n    # 두번째 3x3 Conv->Batch Norm->ReLU 수행\n    # 3x3이 아닌 다른 kernel size도 구성 가능할 수 있도록 identity_block() 인자로 입력받은 middle_kernel_size를 이용. \n    # Conv 수행 출력 사이즈가 변하지 않도록 padding='same'으로 설정. filter 개수는 이전의 1x1 filter개수와 동일.  \n    x = Conv2D(filters=filter2, kernel_size=middle_kernel_size, padding='same', kernel_initializer='he_normal', name=conv_name_base+'2b')(x)\n    x = BatchNormalization(axis=3, name=bn_name_base+'2b')(x)\n    x = Activation('relu')(x)\n    \n    # 마지막 1x1 Conv->Batch Norm 수행. ReLU를 수행하지 않음에 유의.\n    # filter 크기는 input_tensor channel 차원 개수로 원복\n    x = Conv2D(filters=filter3, kernel_size=(1, 1), kernel_initializer='he_normal', name=conv_name_base+'2c')(x)\n    x = BatchNormalization(axis=3, name=bn_name_base+'2c')(x)\n    # Residual Block 수행 결과와 input_tensor를 합한다. \n    x = Add()([input_tensor, x])\n    # 또는 x = add([x, input_tensor]) 와 같이 구현할 수도 있음. \n\n    # 마지막으로 identity block 내에서 최종 ReLU를 적용\n    x = Activation('relu')(x)\n    \n    return x","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 위에서 생성한 identity_block()을 호출하여 어떻게 identity block이 구성되어 있는지 확인"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.layers import Input\nfrom tensorflow.keras.models import Model\n\n# input_tensor로 임의의 Feature Map size를 생성. \ninput_tensor = Input(shape=(56, 56, 256), name='test_input')\n# input_tensor의 channel수는 256개임. filters는 256의 1/4 filter수로 차원 축소후 다시 마지막 1x1 Conv에서 256으로 복원\nfilters = [64, 64, 256]\n# 중간 Conv 커널 크기는 3x3\nkernel_size = (3, 3)\nstage = 2\nblock = 'a'\n\n# identity_block을 호출하고 layer들이 어떻게 구성되어 있는지 확인하기 위해서 model로 구성하고 summary()호출 \noutput = identity_block(input_tensor, kernel_size, filters, stage, block)\nidentity_layers = Model(inputs=input_tensor, outputs=output)\nidentity_layers.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### identity block을 연속으로 이어서 하나의 Stage 구성.\n* 아래는 input tensor의 크기가 feature map 생성시 절반으로 줄지 않음. input tensor의 크기가 절반으로 줄수 있도록 구성 필요.\n* 동일한 Stage 내에서 feature map의 크기는 그대로 대신, block내에서 filter 개수는 변화"},{"metadata":{"trusted":true},"cell_type":"code","source":"input_tensor = Input(shape=(56, 56, 256), name='test_input')\nx = identity_block(input_tensor, middle_kernel_size=3, filters=[64, 64, 256], stage=2, block='a')\nx = identity_block(x, middle_kernel_size=3, filters=[64, 64, 256], stage=2, block='b')\noutput = identity_block(x, middle_kernel_size=3, filters=[64, 64, 256], stage=2, block='c')\nidentity_layers = Model(inputs=input_tensor, outputs=output)\nidentity_layers.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 각 stage내의 첫번째 identity block에서 입력 feature map의 크기를 절반으로 줄이는 block을 생성하는 함수 conv_block() 만들기\n* conv_block() 함수는 앞에서 구현한 identity_block()함수과 거의 유사하나 입력 feature map의 크기를 절반으로 줄이고 shortcut 전달시 1x1 conv stride 2 적용\n* 단 첫번째 Stage의 첫번째 block에서는 이미 입력 feature map이 max pool로 절반이 줄어있는 상태이므로 다시 줄이지 않음. "},{"metadata":{"trusted":true},"cell_type":"code","source":"def conv_block(input_tensor, middle_kernel_size, filters, stage, block, strides=(2, 2)):\n    '''\n    함수 입력 인자 설명\n    input_tensor: 입력 tensor\n    middle_kernel_size: 중간에 위치하는 kernel 크기. identity block내에 있는 두개의 conv layer중 1x1 kernel이 아니고, 3x3 kernel임. \n                        3x3 커널 이외에도 5x5 kernel도 지정할 수 있게 구성. \n    filters: 3개 conv layer들의 filter개수를 list 형태로 입력 받음. 첫번째 원소는 첫번째 1x1 filter 개수, 두번째는 3x3 filter 개수, \n             세번째는 마지막 1x1 filter 개수\n    stage: identity block들이 여러개가 결합되므로 이를 구분하기 위해서 설정. 동일한 filter수를 가지는 identity block들을  동일한 stage로 설정.  \n    block: 동일 stage내에서 identity block을 구별하기 위한 구분자\n    strides: 입력 feature map의 크기를 절반으로 줄이기 위해서 사용. Default는 2이지만, \n             첫번째 Stage의 첫번째 block에서는 이미 입력 feature map이 max pool로 절반이 줄어있는 상태이므로 다시 줄이지 않기 위해 1을 호출해야함 \n    ''' \n    \n    # filters로 list 형태로 입력된 filter 개수를 각각 filter1, filter2, filter3로 할당. \n    # filter은 첫번째 1x1 filter 개수, filter2는 3x3 filter개수, filter3는 마지막 1x1 filter개수\n    filter1, filter2, filter3 = filters\n    # conv layer와 Batch normalization layer각각에 고유한 이름을 부여하기 위해 설정. 입력받은 stage와 block에 기반하여 이름 부여\n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n    \n    # 이전 layer에 입력 받은 input_tensor(함수인자로 입력받음)를 기반으로 첫번째 1x1 Conv->Batch Norm->Relu 수행. \n    # 입력 feature map 사이즈를 1/2로 줄이기 위해 strides인자를 입력  \n    x = Conv2D(filters=filter1, kernel_size=(1, 1), strides=strides, kernel_initializer='he_normal', name=conv_name_base+'2a')(input_tensor)\n    # Batch Norm적용. 입력 데이터는 batch 사이즈까지 포함하여 4차원임(batch_size, height, width, channel depth)임\n    # Batch Norm의 axis는 channel depth에 해당하는 axis index인 3을 입력.(무조건 channel이 마지막 차원의 값으로 입력된다고 가정. )\n    x = BatchNormalization(axis=3, name=bn_name_base+'2a')(x)\n    # ReLU Activation 적용. \n    x = Activation('relu')(x)\n    \n    # 두번째 3x3 Conv->Batch Norm->ReLU 수행\n    # 3x3이 아닌 다른 kernel size도 구성 가능할 수 있도록 identity_block() 인자로 입력받은 middle_kernel_size를 이용. \n    # Conv 수행 출력 사이즈가 변하지 않도록 padding='same'으로 설정. filter 개수는 이전의 1x1 filter개수와 동일.  \n    x = Conv2D(filters=filter2, kernel_size=middle_kernel_size, padding='same', kernel_initializer='he_normal', name=conv_name_base+'2b')(x)\n    x = BatchNormalization(axis=3, name=bn_name_base+'2b')(x)\n    x = Activation('relu')(x)\n    \n    # 마지막 1x1 Conv->Batch Norm 수행. ReLU를 수행하지 않음에 유의.\n    # filter 크기는 input_tensor channel 차원 개수로 원복\n    x = Conv2D(filters=filter3, kernel_size=(1, 1), kernel_initializer='he_normal', name=conv_name_base+'2c')(x)\n    x = BatchNormalization(axis=3, name=bn_name_base+'2c')(x)\n    \n    # shortcut을 1x1 conv 수행, filter3가 입력 feature map의 filter 개수\n    shortcut = Conv2D(filter3, (1, 1), strides=strides, kernel_initializer='he_normal', name=conv_name_base+'1')(input_tensor)\n    shortcut = BatchNormalization(axis=3, name=bn_name_base+'1')(shortcut)\n    \n    # Residual Block 수행 결과와 1x1 conv가 적용된 shortcut을 합한다. \n    x = add([x, shortcut])\n    \n    # 마지막으로 identity block 내에서 최종 ReLU를 적용\n    x = Activation('relu')(x)\n    \n    return x\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### conv_block()과 identity_block()을 호출하여 stage 구성."},{"metadata":{"trusted":true},"cell_type":"code","source":"input_tensor = Input(shape=(56, 56, 256), name='test_input')\n# conv_block() 호출 시 strides를 2로 설정하여 입력 feature map의 크기를 절반으로 줄임. strides=1이면 크기를 그대로 유지\nx = conv_block(input_tensor, middle_kernel_size=3, filters=[64, 64, 256], strides=2, stage=2, block='a')\nx = identity_block(x, middle_kernel_size=3, filters=[64, 64, 256], stage=2, block='b')\noutput = identity_block(x, middle_kernel_size=3, filters=[64, 64, 256], stage=2, block='c')\nidentity_layers = Model(inputs=input_tensor, outputs=output)\nidentity_layers.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### input image를 7x7 Conv 변환하고 Max Pooling 적용 로직을 별도 함수로 구현.\n* O = (I - F + 2P)/S + 1, I는 Input size, F는 filter의 kernel 크기, P는 padding, S는 Stride\n* (224 - 7)/2 + 1 = 109.5 = 109가 됨. 따라서 112x112 로 출력하기 위해 ZeroPadding2D(3, 3)수행\n* 112x112로 MaxPooling 을 (3, 3) pool size로 stride 2로 수행하므로 56x56으로 출력하기 위해 ZeroPadding2D(1,1) 수행"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.layers import ZeroPadding2D, MaxPooling2D\n\ndef do_first_conv(input_tensor):\n    # 7x7 Conv 연산 수행하여 feature map 생성하되 input_tensor 크기(image 크기)의 절반으로 생성.  filter 개수는 64개 \n    # 224x224 를 input을 7x7 conv, strides=2로 112x112 출력하기 위해 Zero padding 적용. \n    x = ZeroPadding2D(padding=(3, 3), name='conv1_pad')(input_tensor)\n    x = Conv2D(64, (7, 7), strides=(2, 2), padding='valid', kernel_initializer='he_normal', name='conv')(x)\n    x = BatchNormalization(axis=3, name='bn_conv1')(x)\n    x = Activation('relu')(x)\n    # 다시 feature map 크기를 MaxPooling으로 절반으로 만듬. 56x56으로 출력하기 위해 zero padding 적용. \n    x = ZeroPadding2D(padding=(1, 1), name='pool1_pad')(x)\n    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n    \n    return x\n\ninput_tensor = Input(shape=(224, 224, 3))\noutput = do_first_conv(input_tensor)\nmodel = Model(inputs=input_tensor, outputs=output)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ResNet 50 모델 생성.\n* 앞에서 생성한 conv_block()과 identity_block()을 호출하여 ResNet 50 모델 생성. "},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\nfrom tensorflow.keras.optimizers import Adam , RMSprop \nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint , LearningRateScheduler\n\ndef create_resnet(in_shape=(224, 224, 3), n_classes=10):\n    input_tensor = Input(shape=in_shape)\n    \n    #첫번째 7x7 Conv와 Max Polling 적용.  \n    x = do_first_conv(input_tensor)\n    \n    # stage 2의 conv_block과 identity block 생성. stage2의 첫번째 conv_block은 strides를 1로 하여 크기를 줄이지 않음. \n    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n    \n    # stage 3의 conv_block과 identity block 생성. stage3의 첫번째 conv_block은 strides를 2(default)로 하여 크기를 줄임 \n    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n\n    # stage 4의 conv_block과 identity block 생성. stage4의 첫번째 conv_block은 strides를 2(default)로 하여 크기를 줄임\n    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n\n    # stage 5의 conv_block과 identity block 생성. stage5의 첫번째 conv_block은 strides를 2(default)로 하여 크기를 줄임\n    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n    \n    # classification dense layer와 연결 전 GlobalAveragePooling 수행 \n    x = GlobalAveragePooling2D(name='avg_pool')(x)\n    x = Dropout(rate=0.5)(x)\n    x = Dense(200, activation='relu', name='fc_01')(x)\n    x = Dropout(rate=0.5)(x)\n    output = Dense(n_classes, activation='softmax', name='fc_final')(x)\n    \n    model = Model(inputs=input_tensor, outputs=output, name='resnet50')\n    model.summary()\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model =  create_resnet(in_shape=(224,224,3), n_classes=10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### CIFAR10 데이터 세트로 ResNet 모델 학습 및 성능 테스트"},{"metadata":{"trusted":true},"cell_type":"code","source":"IMAGE_SIZE = 128\nBATCH_SIZE = 64","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### (기존 사용한) 데이터 전처리/인코딩/스케일링 함수 및 CIFAR_Dataset 선언"},{"metadata":{"trusted":true},"cell_type":"code","source":"import random as python_random\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.datasets import cifar10\nfrom tensorflow.keras.utils import Sequence\nimport cv2\nimport sklearn\n\ndef zero_one_scaler(image):\n    return image/255.0\n\ndef get_preprocessed_ohe(images, labels, pre_func=None):\n    # preprocessing 함수가 입력되면 이를 이용하여 image array를 scaling 적용.\n    if pre_func is not None:\n        images = pre_func(images)\n    # OHE 적용    \n    oh_labels = to_categorical(labels)\n    return images, oh_labels\n\n# 학습/검증/테스트 데이터 세트에 전처리 및 OHE 적용한 뒤 반환 \ndef get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021):\n    # 학습 및 테스트 데이터 세트를  0 ~ 1사이값 float32로 변경 및 OHE 적용. \n    train_images, train_oh_labels = get_preprocessed_ohe(train_images, train_labels)\n    test_images, test_oh_labels = get_preprocessed_ohe(test_images, test_labels)\n    \n    # 학습 데이터를 검증 데이터 세트로 다시 분리\n    tr_images, val_images, tr_oh_labels, val_oh_labels = train_test_split(train_images, train_oh_labels, test_size=valid_size, random_state=random_state)\n    \n    return (tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels )\n\nfrom tensorflow.keras.utils import Sequence\nimport cv2\nimport sklearn\n\n# 입력 인자 images_array labels는 모두 numpy array로 들어옴. \n# 인자로 입력되는 images_array는 전체 32x32 image array임. \nclass CIFAR_Dataset(Sequence):\n    def __init__(self, images_array, labels, batch_size=BATCH_SIZE, augmentor=None, shuffle=False, pre_func=None):\n        '''\n        파라미터 설명\n        images_array: 원본 32x32 만큼의 image 배열값. \n        labels: 해당 image의 label들\n        batch_size: __getitem__(self, index) 호출 시 마다 가져올 데이터 batch 건수\n        augmentor: albumentations 객체\n        shuffle: 학습 데이터의 경우 epoch 종료시마다 데이터를 섞을지 여부\n        '''\n        # 객체 생성 인자로 들어온 값을 객체 내부 변수로 할당. \n        # 인자로 입력되는 images_array는 전체 32x32 image array임.\n        self.images_array = images_array\n        self.labels = labels\n        self.batch_size = batch_size\n        self.augmentor = augmentor\n        self.pre_func = pre_func\n        # train data의 경우 \n        self.shuffle = shuffle\n        if self.shuffle:\n            # 객체 생성시에 한번 데이터를 섞음. \n            #self.on_epoch_end()\n            pass\n    \n    # Sequence를 상속받은 Dataset은 batch_size 단위로 입력된 데이터를 처리함. \n    # __len__()은 전체 데이터 건수가 주어졌을 때 batch_size단위로 몇번 데이터를 반환하는지 나타남\n    def __len__(self):\n        # batch_size단위로 데이터를 몇번 가져와야하는지 계산하기 위해 전체 데이터 건수를 batch_size로 나누되, 정수로 정확히 나눠지지 않을 경우 1회를 더한다. \n        return int(np.ceil(len(self.labels) / self.batch_size))\n    \n    # batch_size 단위로 image_array, label_array 데이터를 가져와서 변환한 뒤 다시 반환함\n    # 인자로 몇번째 batch 인지를 나타내는 index를 입력하면 해당 순서에 해당하는 batch_size 만큼의 데이타를 가공하여 반환\n    # batch_size 갯수만큼 변환된 image_array와 label_array 반환. \n    def __getitem__(self, index):\n        # index는 몇번째 batch인지를 나타냄. \n        # batch_size만큼 순차적으로 데이터를 가져오려면 array에서 index*self.batch_size:(index+1)*self.batch_size 만큼의 연속 데이터를 가져오면 됨\n        # 32x32 image array를 self.batch_size만큼 가져옴. \n        images_fetch = self.images_array[index*self.batch_size:(index+1)*self.batch_size]\n        if self.labels is not None:\n            label_batch = self.labels[index*self.batch_size:(index+1)*self.batch_size]\n        \n        # 만일 객체 생성 인자로 albumentation으로 만든 augmentor가 주어진다면 아래와 같이 augmentor를 이용하여 image 변환\n        # albumentations은 개별 image만 변환할 수 있으므로 batch_size만큼 할당된 image_name_batch를 한 건씩 iteration하면서 변환 수행. \n        # 변환된 image 배열값을 담을 image_batch 선언. image_batch 배열은 float32 로 설정. \n        image_batch = np.zeros((images_fetch.shape[0], IMAGE_SIZE, IMAGE_SIZE, 3), dtype='float32')\n        \n        # batch_size에 담긴 건수만큼 iteration 하면서 opencv image load -> image augmentation 변환(augmentor가 not None일 경우)-> image_batch에 담음. \n        for image_index in range(images_fetch.shape[0]):\n            #image = cv2.cvtColor(cv2.imread(image_name_batch[image_index]), cv2.COLOR_BGR2RGB)\n            # 원본 image를 IMAGE_SIZE x IMAGE_SIZE 크기로 변환\n            image = cv2.resize(images_fetch[image_index], (IMAGE_SIZE, IMAGE_SIZE))\n            # 만약 augmentor가 주어졌다면 이를 적용. \n            if self.augmentor is not None:\n                image = self.augmentor(image=image)['image']\n                \n            # 만약 scaling 함수가 입력되었다면 이를 적용하여 scaling 수행. \n            if self.pre_func is not None:\n                image = self.pre_func(image)\n            \n            # image_batch에 순차적으로 변환된 image를 담음.               \n            image_batch[image_index] = image\n        \n        return image_batch, label_batch\n    \n    # epoch가 한번 수행이 완료 될 때마다 모델의 fit()에서 호출됨. \n    def on_epoch_end(self):\n        if(self.shuffle):\n            #print('epoch end')\n            # 원본 image배열과 label를 쌍을 맞춰서 섞어준다. scikt learn의 utils.shuffle에서 해당 기능 제공\n            self.images_array, self.labels = sklearn.utils.shuffle(self.images_array, self.labels)\n        else:\n            pass","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n### 원-핫 인코딩, 학습/검증/테스트 데이터 세트 분할\n* scaling은 원본 채널별 pixel값 - [103.939, 116.779, 123.68] 적용.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# CIFAR10 데이터 재 로딩 및 OHE 전처리 적용하여 학습/검증/데이터 세트 생성. \n(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\nprint(train_images.shape, train_labels.shape, test_images.shape, test_labels.shape)\n\n(tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels) = \\\n    get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.2, random_state=2021)\nprint(tr_images.shape, tr_oh_labels.shape, val_images.shape, val_oh_labels.shape, test_images.shape, test_oh_labels.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 학습, 검증용 CIFAR_Dataset 생성"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications.resnet50 import preprocess_input as resnet_preprocess\n\ntr_ds = CIFAR_Dataset(tr_images, tr_oh_labels, batch_size=BATCH_SIZE, augmentor=None, shuffle=True, pre_func=resnet_preprocess)\nval_ds = CIFAR_Dataset(val_images, val_oh_labels, batch_size=BATCH_SIZE, augmentor=None, shuffle=False, pre_func=resnet_preprocess)\n\nprint(next(iter(tr_ds))[0].shape, next(iter(val_ds))[0].shape)\nprint(next(iter(tr_ds))[1].shape, next(iter(val_ds))[1].shape)\n# 채널별 값 - [103.939, 116.779, 123.68]\nprint(next(iter(tr_ds))[0][0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ResNet50 모델 생성 후 학습 및 성능 검증\n* 초기 learning_rate 0.001\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"resnet_model = create_resnet(in_shape=(128, 128, 3), n_classes=10)\n\nresnet_model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n\n# 5번 iteration내에 validation loss가 향상되지 않으면 learning rate을 기존 learning rate * 0.2로 줄임.  \nrlr_cb = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, mode='min', verbose=1)\nely_cb = EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)\n\nhistory = resnet_model.fit(tr_ds, epochs=30, \n                    #steps_per_epoch=int(np.ceil(tr_images.shape[0]/BATCH_SIZE)),\n                    validation_data=val_ds, \n                    #validation_steps=int(np.ceil(val_images.shape[0]/BATCH_SIZE)), \n                    callbacks=[rlr_cb, ely_cb]\n                   )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_ds = CIFAR_Dataset(test_images, test_oh_labels, batch_size=BATCH_SIZE, augmentor=None, shuffle=False, pre_func=resnet_preprocess)\nresnet_model.evaluate(test_ds)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ResNet50 Pretrained 모델로 학습/평가"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications import ResNet50\n\ninput_tensor = Input(shape=(128, 128, 3))\nbase_model = ResNet50(include_top=False, weights=None, input_tensor=input_tensor)\nbm_output = base_model.output\n\n# classification dense layer와 연결 전 GlobalAveragePooling 수행 \nx = GlobalAveragePooling2D(name='avg_pool')(bm_output)\nx = Dropout(rate=0.5)(x)\nx = Dense(200, activation='relu', name='fc_01')(x)\nx = Dropout(rate=0.5)(x)\noutput = Dense(10, activation='softmax', name='fc_final')(x)\n\npr_model = Model(inputs=input_tensor, outputs=output, name='resnet50')\npr_model.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pr_model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n\nhistory = pr_model.fit(tr_ds, epochs=30, \n                    validation_data=val_ds,\n                    callbacks=[rlr_cb, ely_cb]\n                   )\n\ntest_ds = CIFAR_Dataset(test_images, test_oh_labels, batch_size=BATCH_SIZE, augmentor=None, shuffle=False, pre_func=resnet_preprocess)\npr_model.evaluate(test_ds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}