{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Keras의 Pretrained 모델 로딩 및 모델 구조 확인. "},{"metadata":{"trusted":true},"cell_type":"code","source":"#from tensorflow.keras.applications.vgg16 import VGG16\n#from tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.applications import VGG16, ResNet50, ResNet50V2, Xception","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = VGG16()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = VGG16(input_shape=(32, 32, 3), include_top=False, weights='imagenet')\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Keras의 Model 역시 Functional임. "},{"metadata":{"trusted":true},"cell_type":"code","source":"print('model:', model)\nprint('model output:', model.output)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Pretrained 모델을 기반으로 CIFAR 10 분류 모델 재 생성. "},{"metadata":{"trusted":true},"cell_type":"code","source":"IMAGE_SIZE = 32\nBATCH_SIZE = 64","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\nfrom tensorflow.keras.optimizers import Adam , RMSprop \nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint , LearningRateScheduler\n\n# include_top=False로 기존 imagenet용 classifier 층들을 다 제거. weight는 전이학습을 위해 imagenet 학습된 weight를 초기 weight로 사용. \n#input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n#base_model = VGG16(input_tensor=input_tensor, include_top=False, weights='imagenet')\n\nbase_model = VGG16(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), include_top=False, weights='imagenet')\nbm_output = base_model.output\n\n# base model의 output을 입력으로 CIFAR10용 Classification layer를 재 구성. \nx = GlobalAveragePooling2D()(bm_output)\n# x = Dropout(rate=0.5)(x)\nx = Dense(50, activation='relu', name='fc1')(x)\n# x = Dropout(rate=0.2)(x)\noutput = Dense(10, activation='softmax', name='output')(x)\n\n#model = Model(inputs=input_tensor, outputs=output)\nmodel = Model(inputs=base_model.input, outputs=output)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 데이터 전처리 및 ImageDataGenerator로 Augmentation 설정하고 학습용, 검증용 Generator 생성"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport pandas as pd\n\nimport random as python_random\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.datasets import cifar10\n\n# seed 를 설정해서 학습시마다 동일한 결과 유도. 불행히도 의도한 대로 동작하지 않음. \ndef set_random_seed(seed_value):\n    np.random.seed(seed_value)\n    python_random.seed(seed_value)\n    tf.random.set_seed(seed_value)\n\n# 0 ~ 1사이값의 float32로 변경하는 함수\ndef get_preprocessed_data(images, labels, scaling=True):\n    \n    # 학습과 테스트 이미지 array를 0~1 사이값으로 scale 및 float32 형 변형. \n    if scaling:\n        images = np.array(images/255.0, dtype=np.float32)\n    else:\n        images = np.array(images, dtype=np.float32)\n        \n    labels = np.array(labels, dtype=np.float32)\n    \n    return images, labels\n\n# 0 ~ 1사이값 float32로 변경하는 함수 호출 한 뒤 OHE 적용 \ndef get_preprocessed_ohe(images, labels):\n    images, labels = get_preprocessed_data(images, labels, scaling=False)\n    # OHE 적용 \n    oh_labels = to_categorical(labels)\n    return images, oh_labels\n\n# 학습/검증/테스트 데이터 세트에 전처리 및 OHE 적용한 뒤 반환 \ndef get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021):\n    # 학습 및 테스트 데이터 세트를  0 ~ 1사이값 float32로 변경 및 OHE 적용. \n    train_images, train_oh_labels = get_preprocessed_ohe(train_images, train_labels)\n    test_images, test_oh_labels = get_preprocessed_ohe(test_images, test_labels)\n    \n    # 학습 데이터를 검증 데이터 세트로 다시 분리\n    tr_images, val_images, tr_oh_labels, val_oh_labels = train_test_split(train_images, train_oh_labels, test_size=valid_size, random_state=random_state)\n    \n    return (tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels ) \n\n\n# random seed는 2021로 고정.\nset_random_seed(2021)\n# CIFAR10 데이터 재 로딩 및 Scaling/OHE 전처리 적용하여 학습/검증/데이터 세트 생성. \n(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\nprint(train_images.shape, train_labels.shape, test_images.shape, test_labels.shape)\n\n(tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels) = \\\n    get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021)\n\nprint(tr_images.shape, tr_oh_labels.shape, val_images.shape, val_oh_labels.shape, test_images.shape, test_oh_labels.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_generator = ImageDataGenerator(\n    # rotation_range=20,\n    #zoom_range=(0.7, 0.9),\n    horizontal_flip=True,\n    #vertical_flip=True,\n    rescale=1/255.0\n)\nvalid_generator = ImageDataGenerator(rescale=1/255.0)\n\nflow_tr_gen = train_generator.flow(tr_images, tr_oh_labels, batch_size=BATCH_SIZE, shuffle=True)\nflow_val_gen = valid_generator.flow(val_images, val_oh_labels, batch_size=BATCH_SIZE, shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Keras CNN 모델 생성 함수. "},{"metadata":{"trusted":true},"cell_type":"code","source":"IMAGE_SIZE = 32\nBATCH_SIZE = 64","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\nfrom tensorflow.keras.optimizers import Adam , RMSprop \nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint , LearningRateScheduler\n\ndef create_model(verbose=False):\n    \n    input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n    base_model = VGG16(input_tensor=input_tensor, include_top=False, weights='imagenet')\n    bm_output = base_model.output\n\n    x = GlobalAveragePooling2D()(bm_output)\n    #x = Dropout(rate=0.5)(x)\n    x = Dense(50, activation='relu', name='fc1')(x)\n    #x = Dropout(rate=0.2)(x)\n    output = Dense(10, activation='softmax', name='output')(x)\n\n    model = Model(inputs=input_tensor, outputs=output)\n    if verbose:\n        model.summary()\n        \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vgg_model = create_model(verbose=True)\nvgg_model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n\n# 5번 iteration내에 validation loss가 향상되지 않으면 learning rate을 기존 learning rate * 0.2로 줄임.  \nrlr_cb = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, mode='min', verbose=1)\n# 10번 iteration내에 validation loss가 향상되지 않으면 더 이상 학습하지 않고 종료\nely_cb = EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# steps 횟수를 구하기 위해 학습 데이터의 건수와 검증 데이터의 건수를 구함. steps = ceil(학습 데이터 건수/BATCH_SIZE)\ntr_data_len = tr_images.shape[0]\nval_data_len = val_images.shape[0]\nhistory = vgg_model.fit(flow_tr_gen, epochs=40, \n                    steps_per_epoch=int(np.ceil(tr_data_len/BATCH_SIZE)), \n                    validation_data=flow_val_gen, validation_steps=int(np.ceil(val_data_len/BATCH_SIZE)),\n                    callbacks=[rlr_cb, ely_cb])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_generator = ImageDataGenerator(rescale=1/255.0)\nflow_test_gen = test_generator.flow(test_images, test_oh_labels, batch_size=BATCH_SIZE, shuffle=False)\nvgg_model.evaluate(flow_test_gen)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\n\ndef show_history(history):\n    plt.figure(figsize=(8, 4))\n    plt.yticks(np.arange(0, 1, 0.05))\n    plt.xticks(np.arange(0, 30, 2))\n    plt.plot(history.history['accuracy'], label='train')\n    plt.plot(history.history['val_accuracy'], label='valid')\n    plt.legend()\n    \nshow_history(history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 지금까지의 로직들을 함수화 "},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\nfrom tensorflow.keras.optimizers import Adam , RMSprop \nfrom tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint , LearningRateScheduler\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimport tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport cv2\n\nimport random as python_random\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.datasets import cifar10\n\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.applications import ResNet50V2\nfrom tensorflow.keras.applications import Xception\n\n# seed 를 설정해서 학습시마다 동일한 결과 유도. 불행히도 의도한 대로 동작하지 않음. \ndef set_random_seed(seed_value):\n    np.random.seed(seed_value)\n    python_random.seed(seed_value)\n    tf.random.set_seed(seed_value)\n\n# 0 ~ 1사이값의 float32로 변경하는 함수\ndef get_preprocessed_data(images, labels, scaling=True):\n    \n    # 학습과 테스트 이미지 array를 0~1 사이값으로 scale 및 float32 형 변형. \n    if scaling:\n        images = np.array(images/255.0, dtype=np.float32)\n    else:\n        images = np.array(images, dtype=np.float32)\n        \n    labels = np.array(labels, dtype=np.float32)\n    \n    return images, labels\n\n# 0 ~ 1사이값 float32로 변경하는 함수 호출 한 뒤 OHE 적용 \ndef get_preprocessed_ohe(images, labels):\n    images, labels = get_preprocessed_data(images, labels, scaling=False)\n    # OHE 적용 \n    oh_labels = to_categorical(labels)\n    return images, oh_labels\n\n# 학습/검증/테스트 데이터 세트에 전처리 및 OHE 적용한 뒤 반환 \ndef get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021):\n    # 학습 및 테스트 데이터 세트를  0 ~ 1사이값 float32로 변경 및 OHE 적용. \n    train_images, train_oh_labels = get_preprocessed_ohe(train_images, train_labels)\n    test_images, test_oh_labels = get_preprocessed_ohe(test_images, test_labels)\n    \n    # 학습 데이터를 검증 데이터 세트로 다시 분리\n    tr_images, val_images, tr_oh_labels, val_oh_labels = train_test_split(train_images, train_oh_labels, test_size=valid_size, random_state=random_state)\n    \n    return (tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels ) \n\n# 입력 image의 크기를 resize 값 만큼 증가. CIFAR10의 이미지가 32x32로 작아서 마지막 feature map의 크기가 1로 되어 모델 성능이 좋지 않음. \n# 마지막 feature map의 크기를 2로 만들기 위해 resize를 64로 하여 입력 이미지 크기를 변경. 단 메모리를 크게 소비하므로 64이상은 kernel이 다운됨. \ndef get_resized_images(images, resize=64):\n    image_cnt = images.shape[0]\n    resized_images = np.zeros((images.shape[0], resize, resize, 3))\n    for i in range(image_cnt):\n        resized_image = cv2.resize(images[i], (resize, resize))\n        resized_images[i] = resized_image\n    \n    return resized_images\n\ndef create_model(model_name='vgg16', verbose=False):\n    \n    input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n    if model_name == 'vgg16':\n        base_model = VGG16(input_tensor=input_tensor, include_top=False, weights='imagenet')\n    elif model_name == 'resnet50':\n        base_model = ResNet50V2(input_tensor=input_tensor, include_top=False, weights='imagenet')\n    elif model_name == 'xception':\n        base_model = Xception(input_tensor=input_tensor, include_top=False, weights='imagenet')\n    \n    bm_output = base_model.output\n\n    x = GlobalAveragePooling2D()(bm_output)\n    if model_name != 'vgg16':\n        x = Dropout(rate=0.5)(x)\n    x = Dense(50, activation='relu', name='fc1')(x)\n    output = Dense(10, activation='softmax', name='output')(x)\n\n    model = Model(inputs=input_tensor, outputs=output)\n    model.summary()\n        \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IMAGE_SIZE = 32\nBATCH_SIZE = 64\n\ndef do_cifar10_train_evaluation(image_size=IMAGE_SIZE, model_name='vgg16'):\n    set_random_seed(2021)\n    # CIFAR10 데이터 재 로딩 및 Scaling/OHE 전처리 적용하여 학습/검증/데이터 세트 생성. \n    (train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n    (tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels) = \\\n        get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021)\n    print('데이터 세트 shape:', tr_images.shape, tr_oh_labels.shape, val_images.shape, val_oh_labels.shape, test_images.shape, test_oh_labels.shape)\n    \n    # 만약 image_size가 32보다 크면 이미지 크기 재조정. \n    if image_size > 32:\n        tr_images = get_resized_images(tr_images)\n        val_images = get_resized_images(val_images)\n        test_images = get_resized_images(test_images)\n    \n    # 학습/검증/테스트용 ImageDataGenerator와 flow로 pipeline 생성. \n    train_generator = ImageDataGenerator(\n        horizontal_flip=True,\n        rescale=1/255.0\n    )\n    valid_generator = ImageDataGenerator(rescale=1/255.0)\n    test_generator = ImageDataGenerator(rescale=1/255.0)\n\n    flow_tr_gen = train_generator.flow(tr_images, tr_oh_labels, batch_size=BATCH_SIZE, shuffle=True)\n    flow_val_gen = valid_generator.flow(val_images, val_oh_labels, batch_size=BATCH_SIZE, shuffle=False)\n    flow_test_gen = train_generator.flow(test_images, test_oh_labels, batch_size=BATCH_SIZE, shuffle=False)\n    \n    # model_name 에 따른 모델 생성하고 모델 학습 및 검증 수행. \n    model = create_model(model_name=model_name, verbose=True)\n    model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n\n    # 5번 iteration내에 validation loss가 향상되지 않으면 learning rate을 기존 learning rate * 0.2로 줄임.  \n    rlr_cb = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, mode='min', verbose=1)\n    # 10번 iteration내에 validation loss가 향상되지 않으면 더 이상 학습하지 않고 종료\n    ely_cb = EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)\n    \n    tr_data_len = tr_images.shape[0]\n    val_data_len = val_images.shape[0]\n    history = model.fit(flow_tr_gen, epochs=40, \n                        steps_per_epoch=int(np.ceil(tr_data_len/BATCH_SIZE)), \n                        validation_data=flow_val_gen, validation_steps=int(np.ceil(val_data_len/BATCH_SIZE)),\n                        callbacks=[rlr_cb, ely_cb])\n    # 테스트 데이터 세트로 모델 성능 검증 \n    evaluation_result = model.evaluate(flow_test_gen)\n    print('테스트 데이터 세트 evaluation 결과:', evaluation_result)\n    return history, evaluation_result\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\n\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 만약 image_size를 64로 하려면 반드시 RAM이 여유분이 충분히 있는지 확인\nhistory, evaluation_result = do_cifar10_train_evaluation(image_size=64, model_name='xception')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('테스트 데이터세트 검증 결과:', evaluation_result)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\n\ndef show_history(history):\n    plt.figure(figsize=(8, 4))\n    plt.yticks(np.arange(0, 1, 0.05))\n    plt.xticks(np.arange(0, 30, 2))\n    plt.plot(history.history['accuracy'], label='train')\n    plt.plot(history.history['val_accuracy'], label='valid')\n    plt.legend()\n    \nshow_history(history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}